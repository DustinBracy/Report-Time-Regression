---
title: "Team DAY Project"
author: "Dustin Bracy, Adam Ruthford, Yang Zhang"
date: "1/23/2020"
---

```{r LoadDataLibraries}    
library(tidyverse)
library(data.table) #for %like% function
library(xml2)
library(purrr)
library(lubridate)
library(tictoc)
library(kableExtra)
library(car)

tic('total runtime')
load("./data/reports.RData")
load("./data/customGroups.RData")
load("./data/currencyCode.RData")

```

### Notes on Binning HourOfDay and Filtering by server
The HourOfDay variable is going to be binned so that we can examine the time of day as a categorical variable. This is in an effort to determine the best time of the day to run one of or schedule new reports. Servers 1 and 5 are test and development servers. Thus they do not impact the run times for production data.

```{r FilterAndBin}
reports$HourBinned <- case_when(reports$HourOfDay %in% c("06","07") ~ "0607",
                                    reports$HourOfDay %in% c("08","09") ~ "0809",
                                    reports$HourOfDay %in% c("10","11")~ "1011",
                                    reports$HourOfDay %in% c("12","13")~ "1213",
                                    reports$HourOfDay %in% c("14","15")~ "1415",
                                    reports$HourOfDay %in% c("16","17")~ "1617",
                                    reports$HourOfDay %in% c("18","19","20","21","22","23")~ "1823",
                                    reports$HourOfDay %in% c("00","01","02","03","04","05")~ "0005",
                                    TRUE~"OTHER")

```

## Two way Anova

### Unlogged response variable Summary Stats and ANOVA table


```{r UnloggedResponseSummary}
model.fit.HrBnSrv <- aov(ReportDeliveryTime~Server+HourBinned+HourBinned:Server, data = reports)
Anova(model.fit.HrBnSrv,type=3,singular.ok=FALSE)

mysummary<-function(x){
  result<-c(length(x),mean(x),sd(x),sd(x)/length(x))
  names(result)<-c("N","Mean","SD","SE")
  return(result)
}

servestats <-aggregate(ReportDeliveryTime~Server,data=reports,mysummary)
servestats.df <- data.frame(servestats[,1:1],servestats[,-(1)])
servestats.df

hourstats <-aggregate(ReportDeliveryTime~HourBinned,data=reports,mysummary)
hourstats.df <- data.frame(hourstats[,1:1],hourstats[,-(1)])
hourstats.df

sumstats<-aggregate(ReportDeliveryTime~HourBinned:Server,data=reports,mysummary)
sumstats<-cbind(sumstats[,1:2],sumstats[,-(1:2)])
head(sumstats, 30)

```

### Discussion
ANOVA table does show that interaction as well as explanatory variables are significant. The summary statistics include big differences in standard deviation.

### Unlogged response variable Residual plots

```{r UnloggedResponseResidual}
myfits<-data.frame(fitted.values=model.fit.HrBnSrv$fitted.values,residuals=model.fit.HrBnSrv$residuals)

#Residual vs Fitted

plot1<-ggplot(myfits,aes(x=fitted.values,y=residuals))+ylab("Residuals")+
  xlab("Predicted")+geom_point()+ggtitle("Log ReportDeliveryTime Residuals")

#QQ plot of residuals  #Note the diagonal abline is only good for qqplots of normal data.
plot2<-ggplot(myfits,aes(sample=residuals))+
  stat_qq()+geom_abline(intercept=mean(myfits$residuals), slope = sd(myfits$residuals))+
  ggtitle("Log ReportDeliveryTime Q-Q plot")

#Histogram of residuals
plot3<-ggplot(myfits, aes(x=residuals)) + 
  geom_histogram(aes(y=..density..),binwidth=1,color="black", fill="gray")+
  geom_density(alpha=.1, fill="red")+
  ggtitle("Log ReportDeliveryTime Histogram")

plot1
plot2
# plot3 Don't run this one takes too long and we are not going to use it anyway
```

### Discussion
The residual plots is unacceptable. The Q-Q plot demonstrates significant issues as well. A log transformation will be used to correct these problems

## Two way Anova
### Logged response variable Summary Stats and ANOVA table


```{r loggedResponsesummary}
reports$ReportDeliveryTimeLog <- log(reports$ReportDeliveryTime)

model.fit.HrBnSrvlg <- aov(ReportDeliveryTimeLog~Server+HourBinned+HourBinned:Server, data = reports)
Anova(model.fit.HrBnSrvlg,type=3,singular.ok=FALSE)

mysummary<-function(x){
  result<-c(length(x),mean(x),sd(x),sd(x)/length(x))
  names(result)<-c("N","Mean","SD","SE")
  return(result)
}
sumstats<-aggregate(ReportDeliveryTimeLog~HourBinned:Server,data=reports,mysummary)
sumstats<-cbind(sumstats[,1:2],sumstats[,-(1:2)])
sumstats

```

### Discussion
ANOVA table does show that is not significant. The summary statistics standard deviation is more consistent but has intersting patterns.

### Logged response variable Residual plots

```{r loggedResponseResidual}
myfits<-data.frame(fitted.values=model.fit.HrBnSrvlg$fitted.values,residuals=model.fit.HrBnSrvlg$residuals)

#Residual vs Fitted

plot1<-ggplot(myfits,aes(x=fitted.values,y=residuals))+ylab("Residuals")+
  xlab("Predicted")+geom_point()+ggtitle("Log ReportDeliveryTime Residuals")

#QQ plot of residuals  #Note the diagonal abline is only good for qqplots of normal data.
plot2<-ggplot(myfits,aes(sample=residuals))+
  stat_qq()+geom_abline(intercept=mean(myfits$residuals), slope = sd(myfits$residuals))+
  ggtitle("Log ReportDeliveryTime Q-Q plot")

#Histogram of residuals
plot3<-ggplot(myfits, aes(x=residuals)) + 
  geom_histogram(aes(y=..density..),binwidth=1,color="black", fill="gray")+
  geom_density(alpha=.1, fill="red")+
  ggtitle("Log ReportDeliveryTime Histogram")

plot1
plot2
plot3

```

### Discussion
The residual plot shows definite signs of improvement. The Q-Q plot demonstrates significant issues as well. The histogram shows normal distribution

### To Do Contrasts

```{r ContrastsHours}
TukeyHSD(model.fit.HrBnSrvlg,"HourBinned",conf.level=.95)

library(lsmeans) #maybe need eemeans package
contrast.factor<-~HourBinned
mycontrast<-c("1415-1011","1823-1617")
dat<-reports

library(limma)
final.result<-c()
for( j in 1:length(mycontrast)){
contrast.factor.names<-gsub(" ", "", unlist(strsplit(as.character(contrast.factor),split = "*", fixed = T))[-1])
contrast.factor.2 <- vector("list", length(contrast.factor.names))
for (i in 1:length(contrast.factor.names)) {
  contrast.factor.2[[i]] <- levels(dat[, contrast.factor.names[i]])
}
new.factor.levels <- do.call(paste, c(do.call(expand.grid, 
                                              contrast.factor.2), sep = ""))
temp.cont<-mycontrast[j]
contrast2 <- list(comparison = as.vector(do.call(makeContrasts, 
                                                list(contrasts = temp.cont, levels = new.factor.levels))))

contrast.result <- summary(contrast(lsmeans(model.fit, 
                                            contrast.factor), contrast2, by = NULL))

final.result<-rbind(final.result,contrast.result)
}
#Cleaning up and applying bonferroni correction to the number
#of total comparisons investigated.
final.result$contrast<-mycontrast
final.result$bonf<-length(mycontrast)*final.result$p.value
final.result$bonf[final.result$bonf>1]<-1

final.result

```




