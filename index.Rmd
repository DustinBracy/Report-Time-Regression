---
title: "Team DAY Project"
author: "Dustin Bracy, Adam Ruthford, Yang Zhang"
date: "1/23/2020"
output:
  word_document: default
  word: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table) #for %like% function
library(xml2)
library(purrr)
library(lubridate)
library(tictoc)
library(kableExtra)

# import report data:
tic('total runtime')
load("./data/reports.RData")
load("./data/customGroups.RData")
load("./data/currencyCode.RData")

```

## Introduction
We would like to answer the following questions about our data:
1. Can we accurately predict the runtime of our reports?
2. What is the expected average delivery time of a one off report?
3. What are the best & worst times of day, week, or month to run a report?
4. Is there a difference in performance between report servers?
5. What are the biggest impacts on performance of reports?

## Data Description
We have collected a full year worth of report data spanning Jan 2019 - Jan 2020. The available parameter list is very large. A description of fields is avaiable below:

#### Report Parameters:
* GroupFI - Fully Insured Client
* GroupSF - Self Funded Client
* Agents - Specified agents
* CurrencyCode - Collection of different lines of business
* GroupCustom - Collection of different client types
* SchedFreq - Scheduled Report Frequency

#### Report Metrics:
* ReportBytes - size in bytes of completed report
* Server - Server on which the report was built
* FormID - Uniquely identifies collection of report parameters
* QueueID - Uniquely identifies queued reports
* QueuedDateTime - when report entered queue
* RenderStartDateTime - when server began work on queued report(s) in queueID batch
* ReportStartDateTime - when server began work on individual report
* ReportEndDateTime - when server completed work on individual report
* RenderEndDateTime - when server completed work on queued report(s) in queueID batch
* Priority - controlled report parameter

#### Engineered Features:
* ReportBuildTime - ReportEndDateTime less ReportStartDateTime
* ReportDeliveryTime - RenderEndDateTime less QueuedDateTime
* LagTime - RenderEndDateTime less ReportEndDateTime
* QueueTime - RenderStartDateTime less QueuedDateTime
* DayOfMonth - Day of the month report ran
* DayOfWeek - Day of the week report ran
* HourOfDay - Hour of the day report ran
* NumberOfQueuedReports - How many reports are in the queue and/or processing when the report begins rendering


### Report Category Crosswalk:

Eligibility
"Eligibility","Accumulator","EventHistory","COBRA","RedCard","ComPsych"

Miscellaneous
"Miscellaneous"

Reinsurance
"Reinsurance","Aggregate Report"

Professional Liability
"PL"

Actuarial
"Actuarial","ISBReports","Renewal",
**One exception: when rptCategoryDesc = 'renewal' and reportGroup = 'CommissionsTFB' use 'Commissions'**

Finance Commission
"Commissions","CRMOnlineFinance","CommCnt","CommCompare"

Claims
"ClaimsAudit","CMSRepting","Repository","GilsbarPPO","Claims"

Medical Management
"Wellness Repository","MedCom","TVC","MedInsight"

Metrics
"iTrac","TMS","Customer Service","ODR Admin","PortalStats","AutoAdjudication","Genelco","Supervisor"

Extract
"DataExtracts","Large Claims Reports"

Finance Billing
"Billing", "Coverage","Refunds","Credit Card Process","Deposit","CheckRecon","Check Register","FinancePremium", "Premium"



## Exploratory Analysis

```{r ETL pipeline}

# Remove imported reports:
reports <- reports %>% filter(Server != 'IMPSERVICE')

# Convert to factors:
reports$SchedFreq <- as.factor(reports$SchedFreq)
reports$TestProdIndicator <- as.factor(reports$TestProdIndicator)
reports$DelivMthd <- as.factor(reports$DelivMthd)

tic('clean XML')
# Clean up the XML:
reports$XMLResponseStringClean <- str_replace(reports$XMLResponseString, '>>', '>')
reports$XMLResponseStringClean <- str_replace(reports$XMLResponseStringClean, '&', '-and-')
reports$XMLResponseStringClean <- str_replace(reports$XMLResponseStringClean, 'Transaction Entry Date Thru', 'TransactionEntryDateThru')
reports$XMLResponseStringClean <- str_replace(reports$XMLResponseStringClean,'(<AgentCode>.*</AgentCode>)<ODRParameters>','<NewDataSet><ODRParameters>\\1')
toc()

tic('XML to Cols')
# Parse XML values into Columns: (this might take a minute or two each)
reports$GroupCustom <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% '<GroupCustom>', xml_find_all(read_xml(x), './/GroupCustom') %>% xml_text(), NA))
reports$CurrencyCode <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% '<CurrencyCode>', xml_find_all(read_xml(x), './/CurrencyCode') %>% xml_text() %>% toupper(), NA))
reports$groupFI <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% '<GroupFI>', xml_find_all(read_xml(x), './/GroupFI') %>% xml_text(), NA))
reports$groupSF <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% '<GroupSF>', xml_find_all(read_xml(x), './/GroupSF') %>% xml_text(), NA))
reports$Agents <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% '<AgentCode>', xml_find_all(read_xml(x), './/AgentCode') %>% xml_text(), NA))
toc()

# Count commas to determine number of Agents
reports$AgentCount <- ifelse(is.na(reports$Agents), 0, str_count(reports$Agents, ',')+1)


# Join GroupCount to GroupCustom:
reports <- left_join(reports, CustomGroups, by=c('GroupCustom' = 'CustomGroupCode'))


# Capture original GroupCount
reports$CustomGroupCount <- reports$GroupCount


# Function to count groups for currency codes:
getCCgroups <- function(x = c()){
  df <- setNames(data.frame(cCode=str_split(x,','), stringsAsFactors = F),'ccode')
  df <- inner_join(df, CurrencyCodes, by=c('ccode'='CurrencyCode'))
  return(sum(df$GroupCount, na.rm = T))
}

# Build CurrencyCode counts: (this will take a few minutes)
tic("CC Function")
reports$CurrencyCodeGroups <- sapply(reports$CurrencyCode, function(x) ifelse(is.na(x), 0, getCCgroups(x)))
toc()

# Merge counts:
reports$GroupCount <- ifelse(!is.na(reports$groupFI), 1, reports$GroupCount)
reports$GroupCount <- ifelse(!is.na(reports$groupSF), 1, reports$GroupCount)
reports$GroupCount <- ifelse(is.na(reports$GroupCount), reports$CurrencyCodeGroups, reports$GroupCount)
reports$GroupCount <- ifelse(reports$CurrencyCodeGroups < reports$GroupCount & reports$CurrencyCodeGroups > 0, reports$CurrencyCodeGroups, reports$GroupCount)


# Update report categories: Adam



# NAs at a glance:
MissingValues <- sapply(reports, function(x) sum(is.na(x)))
MissingValues %>% kable("html") %>% kable_styling()

# Stash the original data before we drop stuff
reportsOrg <- reports

# Drop columns we don't need:
dropColumns <- c('XMLResponseString','ReportGroupDescription','ReportPath','StatusDesc','NotifiedDateTime','DeletedDateTime','FormDeleted','ProcessId','FormId','QueueId','RunTimeInMinsSecs','RptCategoryId','CurrencyCodeGroups','CustomGroupCount','RptCategoryDesc')
reports <- reports[ , !(names(reports) %in% dropColumns)]


toc()
```



```{r EDA}

# Yang
summary(reports)

unique(reports$ReportGroupDescription)
unique(reports$RptCategoryDesc)


```


## Addressing Objective 1:
	Restatement of Problem and the overall approach to solve it Required

### Model Selection Required
		Type of Selection
			Options: LASSO, RIDGE, ELASTIC NET,
			     Stepwise, Forward, Backward, 
		             	     Manual / Intuition,
			     A mix of all of the above.  	

### Checking Assumptions Required
			Residual Plots
			Influential point analysis (Cook’s D and Leverage)

		Compare Competing Models Optional (Helpful if using 2 model strategy)
			Via:  Training and test set split or CV
                                        Possible Metrics: (ASE, AIC, BIC, adj R2, etc)
	
### Parameter Interpretation
		Interpretation  Required
		Confidence Intervals Required
	
### Final conclusions from the analyses of Objective 1 Required



In addition to overall conclusions, feel free to include additional insights or concerns gleaned from the analysis.  What needs to be done next or how could we do it better next time?  

## Addressing Objective 2
State what route you are going to take 2way ANOVA or Time series and summarize the goal.  Required

### Main Analysis Content Required
	This will depend on the route you take.  I’m leaving it open here to see what you do.

### Conclusion/Discussion Required
		The conclusion should reprise the questions and conclusions of objective 2.

### Appendix Required
	Well commented SAS/R Code Required
 	Graphics and summary tables (Can be placed in the appendix or in the written report itself.)


