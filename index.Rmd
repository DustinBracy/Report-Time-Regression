---
title: "Team DAY Project"
author: "Dustin Bracy, Adam Ruthford, Yang Zhang"
date: "1/23/2020"
output:
  word_document: 
      reference_docx: "wordStyleRef.docx"
  word: default
editor_options:
  chunk_output_type: console
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table) #for %like% function
library(xml2)
library(lubridate)
library(tictoc)
library(kableExtra)
library(gridExtra)
library(olsrr) #residual plot analysis

# import report data:
load("./data/reports.RData")

# wordStyleRef style changes:
## Set margins to .5"
## Heading 1 creates page break before line
## Heading 2 remove space before
## Heading 5 centers text (#####) 

```

##### ![name](./img/reportLogo.jpg)


# Introduction
Gilsbar offers a comprehensive reporting package to both its internal employees and external clients.  As our user base has grown over the last several years, we have seen an increased demand for reports and consequent load on report servers.  Report run times vary significantly, sometimes reports are returned in minutes, and in the worst case: hours.  In order to mitigate server load and improve report response time, we would like to better understand factors affecting delivery time, as well as to be able to provide our users an estimated delivery time of reports.  We would like to answer the following questions about our data:

1. What is the expected average delivery time of a new report?
2. What are the best & worst times of day, week, or month to run a report?
3. Is there a difference in performance between report servers?
4. What are the biggest impacts on performance of reports?

## Data Description
Gilsbar has provided report data spanning a 12 month period from January 2019 through January 2020. The available parameter list is very large, having over 500 parameters used in the past year.  In order to narrow the scope of the project, we focused on completed reports only, and determined the parameters show below would be most useful in predicting report run time. A description of other, non-utilized fields is avaiable below in the appendix. Also listed there is a crosswalk provided which groups like-type reports into 11 categories. 

## Approach Methodology
We'd like to tackle these questions using two separate models for interpretation.  First, we use Multiple Linear Regression techniques to predict runtime using several of the report metrics and features.  Second, we will utilize two-way ANOVA techniques to compare ReportDeliveryTime vs Server, Report Category, and Report Format.

# Exploratory Data Analysis


# Appendix: EDA Plots:

```{r EDA, fig.width=7.25, fig.height=4.5, echo=TRUE}
# Plot Categorical Variables in character or factor

# By Server
e.server <- reports %>% group_by(Server) %>% summarise(Count=n()) %>% ggplot(aes(x=Server, y=Count)) + geom_bar(stat="identity", fill="orange", color="grey40") + labs(title="Reports by Server", x="Server",y="Count") + geom_text(aes(x=Server, y=0.01, label= Count), vjust=-2, size=3, colour="black", fontface="bold",angle=360)

#By SchedFreq
e.freq <- reports %>% group_by(SchedFreq) %>% summarise(Count=n()) %>% ggplot(aes(x=SchedFreq, y=Count)) + geom_bar(stat="identity", fill="orange", color="grey40") + labs(title="Reports by Schedule Frequency", x="Schedule Frequency",y="Count") + geom_text(aes(x=SchedFreq, y=0.01, label= Count), vjust=-2, size=3, colour="black", fontface="bold",angle=360)

#By RptFrmt
e.format <- reports %>% group_by(RptFrmt) %>% summarise(Count=n()) %>% ggplot(aes(x=RptFrmt, y=Count)) + geom_bar(stat="identity", fill="orange", color="grey40") + labs(title="Reports by Report Format", x="Report Format",y="Count") + geom_text(aes(x=RptFrmt, y=0.01, label= Count), vjust=-2, size=3, colour="black", fontface="bold",angle=360)

#By DelivMthd
e.delivery <- reports %>% group_by(DelivMthd) %>% summarise(Count=n()) %>% ggplot(aes(x=DelivMthd, y=Count)) + geom_bar(stat="identity", fill="orange", color="grey40") + labs(title="Reports by Delivery Method", x="Delivery Method",y="Count") + geom_text(aes(x=DelivMthd, y=0.01, label= Count), vjust=-2, size=3, colour="black", fontface="bold",angle=360)

#By Priority
e.priority <- reports %>% group_by(Priority) %>% summarise(Count=n()) %>% ggplot(aes(x=Priority, y=Count)) + geom_bar(stat="identity", fill="orange", color="grey40") + labs(title="Reports by Priority", x="Priority",y="Count") + geom_text(aes(x=Priority, y=0.01, label= Count), vjust=-2, size=3, colour="black", fontface="bold",angle=360)

#By DayOfWeek
e.weekday <- reports %>% group_by(DayOfWeek) %>% summarise(Count=n()) %>% ggplot(aes(x=DayOfWeek, y=Count)) + geom_bar(stat="identity", fill="orange", color="grey40") + labs(title="Reports by Day Of Week", x="DayOfWeek",y="Count") + geom_text(aes(x=DayOfWeek, y=0.01, label= Count), vjust=-2, size=3, colour="black", fontface="bold",angle=360) 

#By HourOfDay
e.hour <- reports %>% group_by(HourOfDay) %>% summarise(Count=n()) %>% ggplot(aes(x=fct_rev(HourOfDay), y=Count)) + geom_bar(stat="identity", fill="orange", color="grey40") + labs(title="Reports by Hour Of Day", x="HourOfDay",y="Count") + geom_text(aes(x=HourOfDay, y=0.01, label= Count), vjust=0.5, hjust=-.25, size=3, colour="black", fontface="bold",angle=360) + coord_flip()

#By DayOfMonth
e.month <- reports %>% group_by(DayOfMonth) %>% summarise(Count=n()) %>% ggplot(aes(x=fct_rev(DayOfMonth), y=Count)) + geom_bar(stat="identity", fill="orange", color="grey40") + labs(title="Reports by Day Of Month", x="DayOfMonth",y="Count") + geom_text(aes(x=DayOfMonth, y=0.01, label= Count), vjust=0.5, hjust=-.25, size=3, colour="black", fontface="bold",angle=360) + coord_flip()

#By ReportCategory
e.category <- reports %>% group_by(ReportCategory) %>% summarise(Count=n()) %>% ggplot(aes(x=fct_rev(ReportCategory), y=Count)) + geom_bar(stat="identity", fill="orange", color="grey40") + labs(title="Reports By Category", x="ReportCategory",y="Count") + geom_text(aes(x=ReportCategory, y=0.01, label= Count), vjust=0.5, hjust=-.25, size=3, colour="black", fontface="bold",angle=360) + coord_flip()

grid.arrange(e.freq, e.priority, e.format, e.delivery,  ncol=2, nrow=2)
grid.arrange(e.server,e.weekday,  ncol=1, nrow=2)
e.category



```


```{r fig.width=7.25, fig.height=7.25}
grid.arrange(e.hour,e.month,  ncol=2, nrow=1)
```



```{r Dustin's MLR options}

# Basic fit: ~ 33% r^2 and 6.65 MSE
#fit <- lm(log(ReportBuildTime)~ReportCategory + GroupCount + GroupCount*ReportCategory, data=reports)

# Better fit:
#fit <- lm(log(ReportBuildTime)~Server+Priority+GroupCount+ReportCategory+DayOfWeek+DayOfMonth+AgentCount+RptFrmt+DelivMthd+HourOfDay, data=reports)

# Better fit with interactions: (takes quite a few minutes) ~41% r^2 and 5.98s MSE
#fit <- lm(log(ReportBuildTime)~ReportCategory + HourOfDay + GroupCount + DayOfMonth +  HourOfDay*ReportCategory + GroupCount*ReportCategory + HourOfDay*DayOfMonth + GroupCount*DayOfMonth, data=reports)

# ReportId fit: (takes a few minutes) ~79% r^2 and 2.83s MSE
fit <- lm(log(ReportBuildTime)~as.factor(ReportId), data=reports)
fit2 <- lm(log(ReportDeliveryTime)~as.factor(ReportId), data=reports)

```

```{r Fit Diagnostics}

########### Report Build Time Section ########### 
summary(fit)

# Split data into test/train (using 90% to increase plotting speed)
trainIndices = sample(1:dim(reports)[1],round(.90 * dim(reports)[1]))
train = reports[trainIndices,]
test = reports[-trainIndices,]

# Make predictions & calculate MSE
p <- predict(fit, interval="predict",newdata = test)
RMSE <- sqrt(mean((p[,1] - log(test$ReportBuildTime))^2))
# Back transform the RMSE:
exp(RMSE)

# Plot the predictions vs test data:
preds <- data.frame(cbind(log(test$ReportBuildTime), p[,1]))

# raw log data:
plot(log(test$ReportBuildTime), p[,1])

# pretty raw log data:
ggplot(preds, aes(log(test$ReportBuildTime), p[,1])) + geom_point() + labs (x="Predicted Log Seconds", y="Actual Log Seconds")

# back transformed data: (note the outliers)
ggplot(preds, aes(test$ReportBuildTime, exp(p[,1]))) + geom_point() + labs (x="Predicted Seconds", y="Actual Seconds")

# Zoom in to see same scale:
ggplot(preds, aes(test$ReportBuildTime, exp(p[,1]))) + geom_point() + labs (x="Predicted Seconds", y="Actual Seconds") + xlim(0, 1500) + ylim(0, 1500) 

########### Report Delivery Time Section ########### 

summary(fit2)

# Make predictions & calculate MSE
p <- predict(fit2, interval="predict",newdata = test)
RMSE <- sqrt(mean((p[,1] - log(test$ReportDeliveryTime))^2))
# Back transform the RMSE:
exp(RMSE)

# Plot the predictions vs test data:
preds <- data.frame(cbind(log(test$ReportDeliveryTime), p[,1]))

# raw log data:
plot(log(test$ReportDeliveryTime), p[,1])

# pretty raw log data:
ggplot(preds, aes(log(test$ReportDeliveryTime), p[,1])) + geom_point() + labs (x="Predicted Log Seconds", y="Actual Log Seconds")

# back transformed data: (note the outliers)
ggplot(preds, aes(test$ReportDeliveryTime, exp(p[,1]))) + geom_point() + labs (x="Predicted Seconds", y="Actual Seconds")

# Zoom in to see same scale:
ggplot(preds, aes(test$ReportDeliveryTime, exp(p[,1]))) + geom_point() + labs (x="Predicted Seconds", y="Actual Seconds") + xlim(0, 20000) + ylim(0, 20000) 


```


```{r TwoWay ANOVA}


```

# Appendix: Features

## Report Parameters
* Agents - Individual AgentIDs 
* CurrencyCode - Collection of different lines of business
* GroupCustom - Collection of different client types
* GroupFI - Fully Insured Client
* GroupSF - Self Funded Client
* ReportID - Uniquely identifies a report
* QueueID - Uniquely identifies a queue of one or more reports
* FormID - Uniquely identifies collection of report parameters 


## Report Metrics
* Priority - Controlled report parameter
* QueuedDateTime - When report entered queue
* RenderStartDateTime - When server began work on queued report(s) in queueID batch
* ReportStartDateTime - When server began work on individual report
* ReportEndDateTime - When server completed work on individual report
* RenderEndDateTime - When server completed work on queued report(s) in queueID batch
* ReportBytes - Size in bytes of completed report
* RptFormat - Format of the report delivered
* SchedFreq - Scheduled Report Frequency
* Server - Server on which the report was built


## Engineered Features
* AgentCount - Number of agents selected
* DayOfMonth - Day of the month report ran
* DayOfWeek - Day of the week report ran
* GroupCount - Number of clients selected
* HourOfDay - Hour of the day report ran
* LagTime - Time report waited for batch to finish (RenderEndDateTime less ReportEndDateTime)
* QueueTime - Time report entered queue (RenderStartDateTime less QueuedDateTime)
* ReportBuildTime - Time spent to build the report (ReportEndDateTime less ReportStartDateTime)
* ReportDeliveryTime - Time user spent waiting for report (RenderEndDateTime less QueuedDateTime)


# Appendix: Report Categories
## Report Category crosswalk: 
|Category|Groups|
|---|---|
|Eligibility|"Eligibility","Accumulator","EventHistory","COBRA","RedCard","ComPsych"|  
|Miscellaneous|"Miscellaneous"|
|Reinsurance|"Reinsurance","Aggregate Report"|
|Professional Liability|"PL"|
|Actuarial|"Actuarial","ISBReports","Renewal", *except when rptCategoryDesc = 'Renewal' and reportGroup = 'CommissionsTFB' use 'Commissions'*|
|Finance Commission|"Commissions","CRMOnlineFinance","CommCnt","CommCompare"|
|Claims|"ClaimsAudit","CMSRepting","Repository","GilsbarPPO","Claims"|
|Medical Management|"Wellness Repository","MedCom","TVC","MedInsight"|
|Metrics|"iTrac","TMS","Customer Service","ODR Admin","PortalStats","AutoAdjudication","Genelco","Supervisor"|
|Extract|"DataExtracts","Large Claims Reports"|
|Finance Billing|"Billing", "Coverage","Refunds","Credit Card Process","Deposit","CheckRecon","Check Register","FinancePremium", "Premium"|

# Appendix: Data Preparation
## ETL of original data

```{r Appendix.ETL pipeline, eval=FALSE}

tic('total runtime')

# Note I have relabeled this originalReports
load("./data/originalReports.RData")
load("./data/customGroups.RData")
load("./data/currencyCode.RData")

# Remove imported reports & dev servers:
reports <- reports %>% filter(Server %in% c('SQLODR2','SQLODR3','SQLODR6'))

# Drop report with bad data:
reports <- reports %>% filter(!is.na(RunTimeSEC))

tic('clean XML')

# Clean up the XML:
reports$XMLResponseStringClean <- str_replace(reports$XMLResponseString, '>>', '>')
reports$XMLResponseStringClean <- str_replace(reports$XMLResponseStringClean, '&', '-and-')
reports$XMLResponseStringClean <- str_replace(reports$XMLResponseStringClean, 'Transaction Entry Date Thru', 'TransactionEntryDateThru')
reports$XMLResponseStringClean <- str_replace(reports$XMLResponseStringClean,'(<AgentCode>.*</AgentCode>)<ODRParameters>','<NewDataSet><ODRParameters>\\1')
toc()

tic('XML to Cols')
# Parse XML values into Columns: (this might take a minute or two each)
reports$GroupCustom <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% '<GroupCustom>', xml_find_all(read_xml(x), './/GroupCustom') %>% xml_text(), NA))
reports$CurrencyCode <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% '<CurrencyCode>', xml_find_all(read_xml(x), './/CurrencyCode') %>% xml_text() %>% toupper(), NA))
reports$groupFI <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% '<GroupFI>', xml_find_all(read_xml(x), './/GroupFI') %>% xml_text(), NA))
reports$groupSF <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% '<GroupSF>', xml_find_all(read_xml(x), './/GroupSF') %>% xml_text(), NA))
reports$Agents <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% '<AgentCode>', xml_find_all(read_xml(x), './/AgentCode') %>% xml_text(), NA))
toc()

# Capture number of days:
tic("Dates")
reports$DateFrom <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% 'DateFrom>\\d+'| x %like% 'DateRangeFrom', str_replace(x, '.*Date(RangeFrom|From)>(\\d+)</.*', '\\2'), NA))
reports$DateThru <- sapply(reports$XMLResponseStringClean, function(x) 
  ifelse(x %like% 'DateThru>\\d+'| x %like% 'DateRangeThru', str_replace(x, '.*Date(RangeThru|Thru)>(\\d+)</.*', '\\2'), NA))

reports$queued <- as_date(reports$QueuedDateTime)
reports$queued <- str_replace_all(reports$queued, "-", "")

reports$DateThru <- ifelse(is.na(reports$DateThru),NA,ifelse((as_date(reports$DateThru) > as_date('20251231') | reports$DateThru == "") & as_date(reports$DateFrom) != as_date(reports$DateThru), reports$queued, reports$DateThru))

reports$NumDays <- ifelse(is.na(reports$DateFrom) | is.na(reports$DateThru) , NA , difftime(as_date(reports$DateThru), as_date(reports$DateFrom) , units = "days"))
reports$NumDays <- ifelse(as_date(reports$DateFrom) == as_date(reports$DateThru), 1, reports$NumDays)
reports$NumDays <- abs(reports$NumDays)

reports$NumDays <- ifelse(reports$XMLResponseStringClean %like% '>(CURRENT|PRIOR)YEAR<', 365, reports$NumDays)
reports$NumDays <- ifelse(reports$XMLResponseStringClean %like% '>(CURRENT|PRIOR)QUARTER<', 91, reports$NumDays)
reports$NumDays <- ifelse(reports$XMLResponseStringClean %like% '>(CURRENT|PRIOR)MONTH<', 30, reports$NumDays)
reports$NumDays <- ifelse(reports$XMLResponseStringClean %like% '>(CURRENT|PRIOR)WEEK<', 7, reports$NumDays)
reports$NumDays <- ifelse(reports$XMLResponseStringClean %like% '>(CURRENT|PRIOR)DAY<', 1, reports$NumDays)
reports$NumDays <- ifelse(reports$XMLResponseStringClean %like% '>ROLLING3MONTHS<', 91, reports$NumDays)
reports$NumDays <- ifelse(reports$XMLResponseStringClean %like% '>ROLLING6MONTHS<', 182, reports$NumDays)
reports$NumDays <- ifelse(reports$XMLResponseStringClean %like% '>ROLLING12MONTHS<', 365, reports$NumDays)
reports$NumDays <- ifelse(reports$XMLResponseStringClean %like% '>ROLLING15MONTHS<', 456, reports$NumDays)
reports$NumDays <- ifelse(reports$XMLResponseStringClean %like% '>ROLLING24MONTHS<', 730, reports$NumDays)
toc()

# Count commas to determine number of Agents
reports$AgentCount <- ifelse(is.na(reports$Agents), 0, str_count(reports$Agents, ',')+1)


# Join GroupCount to GroupCustom:
reports <- left_join(reports, CustomGroups, by=c('GroupCustom' = 'CustomGroupCode'))


# Capture original GroupCount
reports$CustomGroupCount <- reports$GroupCount


# Function to count groups for currency codes:
getCCgroups <- function(x = c()){
  df <- setNames(data.frame(cCode=str_split(x,','), stringsAsFactors = F),'ccode')
  df <- inner_join(df, CurrencyCodes, by=c('ccode'='CurrencyCode'))
  return(sum(df$GroupCount, na.rm = T))
}

# Build CurrencyCode counts: (this will take a few minutes)
tic("CC Function")
reports$CurrencyCodeGroups <- sapply(reports$CurrencyCode, function(x) ifelse(is.na(x), 0, getCCgroups(x)))
toc()

# Merge GroupCounts:
reports$GroupCount <- ifelse(!is.na(reports$groupFI), 1, reports$GroupCount)
reports$GroupCount <- ifelse(!is.na(reports$groupSF), 1, reports$GroupCount)
reports$GroupCount <- ifelse(reports$XMLResponseStringClean %like% '<ExtGroupNumber>', 1, reports$GroupCount)
reports$GroupCount <- ifelse(reports$XMLResponseStringClean %like% '>ALLGROUPS<', 8353, reports$GroupCount)
reports$GroupCount <- ifelse(is.na(reports$GroupCount), reports$CurrencyCodeGroups, reports$GroupCount)
reports$GroupCount <- ifelse(reports$CurrencyCodeGroups < reports$GroupCount & reports$CurrencyCodeGroups > 0, reports$CurrencyCodeGroups, reports$GroupCount)
reports$GroupCount <- ifelse(is.na(reports$GroupCount),8353,reports$GroupCount)
reports$GroupCount <- ifelse((reports$GroupCount == 0),8353,reports$GroupCount)

# Update report categories: Adam


reports$ReportCategory <- case_when(reports$RptCategoryDesc %in% 
                              c("Eligibility","Accumulator","EventHistory","COBRA",
                                "RedCard","ComPsych") ~ "Eligibility",
                            reports$RptCategoryDesc %in% 
                              c("Miscellaneous") ~ "Miscellaneous",
                            reports$RptCategoryDesc %in% 
                              c("Reinsurance","Aggregate Report")~ "Reinsurance",
                            reports$RptCategoryDesc %in% 
                              c("PL")~ "Professional Liability",
                            reports$RptCategoryDesc %in% c("Renewal") & 
                              reports$ReportGroupDescription == "Commissions TFB" ~ "Finance Commission",
                            reports$RptCategoryDesc %in% 
                              c("Actuarial","ISBReports","Renewal")~ "Actuarial",
                            reports$RptCategoryDesc %in% 
                              c("Commissions","CRMOnlineFinance","CommCnt",
                                "CommCompare")~ "Finance Commission",
                            reports$RptCategoryDesc %in% 
                              c("ClaimsAudit","CMSRepting","Repository","GilsbarPPO","Claims")~ "Claims",
                            reports$RptCategoryDesc %in% 
                              c("Wellness Repository","MedCom","TVC","MedInsight")~ "Medical Management",
                            reports$RptCategoryDesc %in% 
                              c("iTrac","TMS","Customer Service","ODR Admin","PortalStats",
                                "AutoAdjudication","Genelco","Supervisor")~ "Metrics",
                            reports$RptCategoryDesc %in% 
                              c("DataExtracts","Large Claims Reports")~ "Extract",
                            reports$RptCategoryDesc %in% 
                              c("Billing", "Coverage","Refunds","Credit Card Process","Deposit"
                                ,"CheckRecon","Check Register","FinancePremium", "Premium")~ "Finance Billing",
                            TRUE~"OTHER")

# Engineered Features - Adam

reports$ReportBuildTime <- as.numeric(difftime(reports$ReportEndDateTime, reports$ReportStartDateTime, units = "secs"))
reports$ReportDeliveryTime <- as.numeric(difftime(reports$RenderEndDateTime, reports$QueuedDateTime, units = "secs"))
reports$LagTime <- as.numeric(difftime(reports$RenderEndDateTime, reports$ReportEndDateTime, units = "secs"))
reports$QueueTime <-  as.numeric(difftime(reports$RenderStartDateTime, reports$QueuedDateTime, units = "secs"))
reports$DayOfMonth  <- format(as_datetime(reports$ReportStartDateTime),"%d")
reports$DayOfWeek <- format(as_datetime(reports$ReportStartDateTime),"%A")
reports$HourOfDay <- format(as_datetime(reports$ReportStartDateTime),"%H")


# NAs at a glance:
MissingValues <- sapply(reports, function(x) sum(is.na(x)))
MissingValues %>% kable("html") %>% kable_styling()

# Drop extreme outliers, reports which are highly likely to be errors:
reports <- reports %>% filter(ReportDeliveryTime < 300000)

# Remove delivery time < 0
reports <- reports %>% filter(ReportDeliveryTime > 0)

# Convert to factors:
reports$SchedFreq <- as.factor(reports$SchedFreq)
reports$TestProdIndicator <- as.factor(reports$TestProdIndicator)
reports$DelivMthd <- as.factor(reports$DelivMthd)
reports$DayOfMonth <- as.factor(reports$DayOfMonth)
reports$DayOfWeek <- as.factor(reports$DayOfWeek)
reports$ReportCategory <- as.factor(reports$ReportCategory)
reports$RptFrmt <- as.factor(reports$RptFrmt)
reports$Priority <- as.factor(reports$Priority)
reports$HourOfDay <- as.factor(reports$HourOfDay)
reports$Server <- as.factor(reports$Server)

# Add some time binning variables:
reports$HourBinned <- case_when(reports$HourOfDay %in% c("06","07") ~ "0607",
                                    reports$HourOfDay %in% c("08","09") ~ "0809",
                                    reports$HourOfDay %in% c("10","11")~ "1011",
                                    reports$HourOfDay %in% c("12","13")~ "1213",
                                    reports$HourOfDay %in% c("14","15")~ "1415",
                                    reports$HourOfDay %in% c("16","17")~ "1617",
                                    reports$HourOfDay %in% c("18","19","20","21","22","23")~ "1823",
                                    reports$HourOfDay %in% c("00","01","02","03","04","05")~ "0005",
                                    TRUE~"OTHER")

reports$TimeBlock3h <- case_when(reports$HourOfDay %in% 
                              c("00","01","02","03","04","05") ~ "Maintenance",
                            reports$HourOfDay %in% 
                              c("06","07","08") ~ "6am-8am",
                            reports$HourOfDay %in% 
                              c("09","10","11")~ "9am-11am",
                            reports$HourOfDay %in% 
                              c("12","13","14")~ "12pm-2pm",
                            reports$HourOfDay %in% 
                              c("15","16","17")~ "3pm-5pm",
                            reports$HourOfDay %in% 
                              c("18","19","20","21","22","23")~ "Overnight",
                            TRUE~"OTHER")

reports$TimeBlock4h <- case_when(reports$HourOfDay %in% 
                              c("00","01","02","03","04","05") ~ "Maintenance",
                            reports$HourOfDay %in% 
                              c("06","07","08","09") ~ "6am-9am",
                            reports$HourOfDay %in% 
                              c("10","11","12","13")~ "10am-1pm",
                            reports$HourOfDay %in% 
                              c("14","15","16","17")~ "2pm-5pm",
                            reports$HourOfDay %in% 
                              c("18","19","20","21","22","23")~ "Overnight",
                            TRUE~"OTHER")


# Stash the original data before we drop columns
reportsOrg <- reports

# Drop columns we don't need:
dropColumns <- c('XMLResponseString','ReportGroupDescription','ReportPath','StatusDesc','NotifiedDateTime','DeletedDateTime','FormDeleted','ProcessId','FormId','QueueId','RunTimeInMinsSecs','RptCategoryId','CurrencyCodeGroups','CustomGroupCount','RptCategoryDesc', 'RuntimeSec', 'NearestStartHour','XMLResponseStringClean','RunTimeSEC','ReportStartDay')

reports <- reports[ , !(names(reports) %in% dropColumns)]

# Save data for analysis:
save(reports, file="./data/reports.RData")
save(reportsOrg, file="./data/reportsFull.RData")

toc()



```




## Addressing Objective 1:
	Restatement of Problem and the overall approach to solve it Required

### Model Selection Required
		Type of Selection
			Options: LASSO, RIDGE, ELASTIC NET,
			     Stepwise, Forward, Backward, 
		             	     Manual / Intuition,
			     A mix of all of the above.  	

### Checking Assumptions Required
			Residual Plots
			Influential point analysis (Cook’s D and Leverage)

		Compare Competing Models Optional (Helpful if using 2 model strategy)
			Via:  Training and test set split or CV
                                        Possible Metrics: (ASE, AIC, BIC, adj R2, etc)
	
### Parameter Interpretation
		Interpretation  Required
		Confidence Intervals Required
	
### Final conclusions from the analyses of Objective 1 Required



In addition to overall conclusions, feel free to include additional insights or concerns gleaned from the analysis.  What needs to be done next or how could we do it better next time?  

## Addressing Objective 2
State what route you are going to take 2way ANOVA or Time series and summarize the goal.  Required

### Main Analysis Content Required
	This will depend on the route you take.  I’m leaving it open here to see what you do.

### Conclusion/Discussion Required
		The conclusion should reprise the questions and conclusions of objective 2.

### Appendix Required
	Well commented SAS/R Code Required
 	Graphics and summary tables (Can be placed in the appendix or in the written report itself.)


